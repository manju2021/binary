{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "################################################################################\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n",
        "\n",
        "################################################################################\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls '/content/drive/My Drive'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji08y6Yi5Psh",
        "outputId": "ab5e454b-50c4-420a-b9fb-ee4ca0a3798f"
      },
      "id": "ji08y6Yi5Psh",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jul 31 08:52:19 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n",
            "| N/A   52C    P8              13W /  72W |      1MiB / 23034MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Your runtime has 56.9 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n",
            "Mounted at /content/drive\n",
            "'Candidate Information and Intake (File responses)'   los\n",
            "'Candidate Information and Intake.gform'\t     'LVPEI Deployment Architecture(2).drawio'\n",
            "'Colab Notebooks'\t\t\t\t     'LVPEI Deployment Architecture(2).jpg'\n",
            "'Copy of NDA template.doc.gdoc'\t\t\t     'LVPEI Deployment Architecture(2).vsdx'\n",
            " data\t\t\t\t\t\t     'LVPEI Sep 2020 Training Feedback.gsheet'\n",
            "'Getting started.pdf'\t\t\t\t     'optigene Dot Net Resumes.zip'\n",
            " keratoconus\t\t\t\t\t     'Snehal Build'\n",
            " kpop\t\t\t\t\t\t      Sujitha.jpg\n",
            " KT\t\t\t\t\t\t     'UI Design'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1LuVXjE-Lg2o"
      },
      "id": "1LuVXjE-Lg2o",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a06e4bf3",
      "metadata": {
        "id": "a06e4bf3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from mlxtend.evaluate import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "import joblib\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import OneSidedSelection\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d1dfe74a",
      "metadata": {
        "id": "d1dfe74a"
      },
      "outputs": [],
      "source": [
        "# modelName = m\n",
        "# X = X_train\n",
        "# y = y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4d967bcb",
      "metadata": {
        "id": "4d967bcb"
      },
      "outputs": [],
      "source": [
        "# Create a function to define parameters for different models\n",
        "def search_space(modelname):\n",
        "    if modelname == \"lr\":\n",
        "        space = dict()\n",
        "        space[\"penalty\"] = [\"none\", \"l2\"]\n",
        "        space[\"solver\"] = [\"newton-cg\", \"lbfgs\"]\n",
        "        space[\"C\"] = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "    elif modelname == \"rf\":\n",
        "        space = dict()\n",
        "        space[\"n_estimators\"] = [30, 50, 100, 200]\n",
        "        space[\"max_features\"] = ['sqrt', 'log2']\n",
        "        space[\"max_depth\"] = [10, 14, 16]\n",
        "        space[\"min_samples_split\"] = [2, 5, 10]\n",
        "        space[\"min_samples_leaf\"] = [1, 2, 5]\n",
        "        space[\"bootstrap\"] = [True, False]\n",
        "        space[\"criterion\"] = [\"gini\", \"entropy\"]\n",
        "\n",
        "        # space[\"n_estimators\"] = [30, 50, 100, 200, 500]\n",
        "        # space[\"max_features\"] = ['sqrt', 'log2']\n",
        "        # space[\"max_depth\"] = [2, 4, 8, 10, 14]\n",
        "        # space[\"min_samples_split\"] = [2, 5, 10, 20]\n",
        "        # space[\"min_samples_leaf\"] = [1, 2, 5, 10]\n",
        "        # space[\"bootstrap\"] = [True, False]\n",
        "        space[\"criterion\"] = [\"gini\", \"entropy\"]\n",
        "\n",
        "        # space[\"n_estimators\"] = [30, 50, 100]\n",
        "        # space[\"max_features\"] = ['sqrt', 'log2']\n",
        "        # space[\"max_depth\"] = [4, 8]\n",
        "        # space[\"min_samples_split\"] = [2, 5]\n",
        "        # space[\"min_samples_leaf\"] = [2, 5]\n",
        "        # space[\"bootstrap\"] = [True, False]\n",
        "        # space[\"criterion\"] = [\"gini\", \"entropy\"]\n",
        "\n",
        "    elif modelname == \"xgb\":\n",
        "        space = dict()\n",
        "        space[\"n_estimators\"] = [100, 200, 300, 500]\n",
        "        space[\"max_depth\"] = [6, 9, 12]\n",
        "        space[\"min_child_weight\"] = [1, 3, 5]\n",
        "        space[\"subsample\"] = [0.4, 0.5, 0.7]\n",
        "        space[\"colsample_bytree\"] = [0.7, 0.8]\n",
        "        space[\"learning_rate\"] = [0.01, 0.05, 0.1]\n",
        "        space[\"gamma\"] = [0.1, 1]\n",
        "        # space[\"reg_alpha\"] = [0, 0.01, 0.1, 1]\n",
        "        # space[\"reg_lambda\"] = [0, 0.01, 0.1, 1]\n",
        "\n",
        "        # space[\"n_estimators\"] = [50, 100, 200, 300, 500]\n",
        "        # space[\"max_depth\"] = [3, 6, 9, 12]\n",
        "        # space[\"min_child_weight\"] = [1, 3, 5, 10]\n",
        "        # space[\"subsample\"] = [0.5, 0.7, 0.8]\n",
        "        # space[\"colsample_bytree\"] = [0.5, 0.7, 0.8]\n",
        "        # space[\"learning_rate\"] = [0.01, 0.05, 0.1]\n",
        "        # space[\"gamma\"] = [0.1, 0.5, 1]\n",
        "        # # space[\"reg_alpha\"] = [0, 0.01, 0.1, 1]\n",
        "        # # space[\"reg_lambda\"] = [0, 0.01, 0.1, 1]\n",
        "\n",
        "        # space[\"n_estimators\"] = [50, 100, 200]\n",
        "        # space[\"max_depth\"] = [6, 9]\n",
        "        # space[\"min_child_weight\"] = [5, 10]\n",
        "        # space[\"subsample\"] = [0.5, 0.7]\n",
        "        # space[\"colsample_bytree\"] = [0.5, 0.7]\n",
        "        # space[\"learning_rate\"] = [0.01, 0.05]\n",
        "        # space[\"gamma\"] = [0.1, 0.5]\n",
        "        # space[\"reg_alpha\"] = [0.01, 0.1]\n",
        "        # space[\"reg_lambda\"] = [0.01, 0.1]\n",
        "\n",
        "    elif modelname == \"dt\":\n",
        "        space = dict()\n",
        "        space[\"max_depth\"] = [2, 4, 8, 10, 20, 30]\n",
        "        space[\"min_samples_split\"] = [2, 5, 10, 20]\n",
        "        space[\"min_samples_leaf\"] = [1, 2, 5, 10]\n",
        "        space[\"criterion\"] = [\"gini\", \"entropy\"]\n",
        "        space[\"splitter\"] = [\"best\", \"random\"]\n",
        "\n",
        "    elif modelname == \"svm\":\n",
        "        space = dict()\n",
        "        # space[\"C\"] = [0.1, 1, 10, 100, 1000]\n",
        "        # space[\"gamma\"] = [0.001, 0.01, 0.1, 1, 10]\n",
        "        # space[\"kernel\"] = [\"linear\", \"rbf\", \"poly\", \"sigmoid\"]\n",
        "        # space[\"degree\"] = [2, 3, 4]\n",
        "        # space[\"coef0\"] = [0.0, 0.1, 0.5, 1.0]\n",
        "\n",
        "        space[\"C\"] = [0.1, 1, 10]\n",
        "        space[\"gamma\"] = [0.001, 0.01]\n",
        "        space[\"kernel\"] = [\"linear\", \"rbf\", \"poly\", \"sigmoid\"]\n",
        "        space[\"degree\"] = [2, 3]\n",
        "        space[\"coef0\"] = [0.0, 0.1]\n",
        "\n",
        "    elif modelname == \"nb\":\n",
        "        space = dict()\n",
        "        space[\"var_smoothing\"] = np.logspace(0, -9, num=10)\n",
        "\n",
        "    elif modelname == \"ada\":\n",
        "        space = dict()\n",
        "        space[\"n_estimators\"] = [100, 200, 400, 500]\n",
        "        space[\"learning_rate\"] = [0.01, 0.1, 0.5, 1]\n",
        "\n",
        "        # space[\"n_estimators\"] = [30, 50, 100, 200, 400, 500]\n",
        "        # space[\"learning_rate\"] = [0.01, 0.1, 0.5, 1]\n",
        "\n",
        "    elif modelname == \"gb\":\n",
        "        space = dict()\n",
        "        space[\"n_estimators\"] = [100, 200, 400, 500]\n",
        "        space[\"max_depth\"] = [3, 5, 10, 12]\n",
        "        space[\"min_samples_split\"] = [2, 5, 10]\n",
        "        space[\"min_samples_leaf\"] = [1, 2, 4]\n",
        "        space[\"learning_rate\"] = [0.05, 0.1]\n",
        "        space[\"subsample\"] = [0.7, 0.8, 0.9]\n",
        "\n",
        "        # space[\"n_estimators\"] = [30, 50, 100, 200, 400, 500]\n",
        "        # space[\"max_depth\"] = [3, 5, 7, 10, 12]\n",
        "        # space[\"min_samples_split\"] = [2, 5, 10]\n",
        "        # space[\"min_samples_leaf\"] = [1, 2, 4]\n",
        "        # space[\"learning_rate\"] = [0.01, 0.1, 0.05]\n",
        "        # space[\"subsample\"] = [0.7, 0.8, 0.9, 1.0]\n",
        "\n",
        "        # space[\"n_estimators\"] = [50, 100]\n",
        "        # space[\"max_depth\"] = [3, 5, 7]\n",
        "        # space[\"min_samples_split\"] = [5, 10]\n",
        "        # space[\"min_samples_leaf\"] = [2, 4]\n",
        "        # space[\"learning_rate\"] = [0.01, 0.15]\n",
        "        # space[\"subsample\"] = [0.7, 0.85]\n",
        "\n",
        "    return space\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "92ee08d1",
      "metadata": {
        "id": "92ee08d1"
      },
      "outputs": [],
      "source": [
        "def plot_learning_curve(estimator, title, X, y, cv=None, n_jobs=None, train_sizes=np.linspace(0.1, 1.0, 5)):\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring='f1')\n",
        "\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    plt.grid()\n",
        "\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "             label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "             label=\"Cross-validation score\")\n",
        "\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt\n",
        "\n",
        "\n",
        "# Base model with randomized search function\n",
        "def modelTraining(modelName, X, y, metric):\n",
        "\n",
        "    if modelName == \"lr\":\n",
        "        model = LogisticRegression()\n",
        "    elif modelName == \"rf\":\n",
        "        model = RandomForestClassifier()\n",
        "    elif modelName == \"xgb\":\n",
        "        model = XGBClassifier()\n",
        "    elif modelName == \"dt\":\n",
        "        model = DecisionTreeClassifier()\n",
        "    elif modelName == \"svm\":\n",
        "        model = SVC()\n",
        "    elif modelName == \"nb\":\n",
        "        model = GaussianNB()\n",
        "    elif modelName == \"ada\":\n",
        "        model = AdaBoostClassifier()\n",
        "    elif modelName == \"gb\":\n",
        "        model = GradientBoostingClassifier()\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model name\")\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    grid = search_space(modelName)\n",
        "\n",
        "    search = GridSearchCV(model, grid, scoring=metric, n_jobs=-1, cv=cv, verbose=3, return_train_score=True)\n",
        "    result = search.fit(X, y)\n",
        "\n",
        "    cv_results = pd.DataFrame(result.cv_results_)\n",
        "    columns_to_display = [\n",
        "        'params',\n",
        "        'mean_train_score',\n",
        "        'std_train_score',\n",
        "        'mean_test_score',\n",
        "        'std_test_score',\n",
        "        'rank_test_score'\n",
        "    ]\n",
        "    cv_results_filtered = cv_results[columns_to_display]\n",
        "    cv_results_filtered\n",
        "\n",
        "    cv_results_filtered['diff'] = cv_results_filtered['mean_train_score'] - cv_results_filtered['mean_test_score']\n",
        "    cv_results_filtered = cv_results_filtered.sort_values(['diff'], ascending=True).reset_index(drop=True)\n",
        "    hyperparameters = cv_results_filtered[cv_results_filtered['rank_test_score'] == 1]['params'].reset_index(drop=True)[0]\n",
        "    hyperparameters\n",
        "\n",
        "    if modelName == \"lr\":\n",
        "        model_v2 = LogisticRegression(**hyperparameters)\n",
        "    elif modelName == \"rf\":\n",
        "        model_v2 = RandomForestClassifier(**hyperparameters)\n",
        "    elif modelName == \"xgb\":\n",
        "        model_v2 = XGBClassifier(**hyperparameters)\n",
        "    elif modelName == \"dt\":\n",
        "        model_v2 = DecisionTreeClassifier(**hyperparameters)\n",
        "    elif modelName == \"svm\":\n",
        "        model_v2 = SVC(**hyperparameters)\n",
        "    elif modelName == \"nb\":\n",
        "        model_v2 = GaussianNB(**hyperparameters)\n",
        "    elif modelName == \"ada\":\n",
        "        model_v2 = AdaBoostClassifier(**hyperparameters)\n",
        "    elif modelName == \"gb\":\n",
        "        model_v2 = GradientBoostingClassifier(**hyperparameters)\n",
        "\n",
        "    model_v2.fit(X, y)\n",
        "\n",
        "    return model_v2, cv_results_filtered\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "26dce8ab",
      "metadata": {
        "id": "26dce8ab"
      },
      "outputs": [],
      "source": [
        "def error_metrics_classification(y_true, y_pred):\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    pres = precision_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    auc = roc_auc_score(y_true, y_pred)\n",
        "\n",
        "    summary = pd.DataFrame([[str(round(acc,3)),\n",
        "                             str(round(pres,3)),\n",
        "                             str(round(f1,3)),\n",
        "                             str(round(recall,3)),\n",
        "                             str(round(auc,3))\n",
        "                            ]],\n",
        "                            columns=['Accuracy', 'Precision',\n",
        "                                     'F1','Recall', 'AUC'])\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "def train_test_metrics(modelObj, X, y, Xt, yt, modelName):\n",
        "    train_metrics = error_metrics_classification(modelObj, X, y, modelName)\n",
        "    train_metrics.columns = train_metrics.columns + \"_train\"\n",
        "    test_metrics = error_metrics_classification(modelObj, Xt, yt, modelName)\n",
        "    test_metrics = test_metrics.drop([\"Search\", \"Model\"], axis=1)\n",
        "    test_metrics.columns = test_metrics.columns + \"_test\"\n",
        "    tt_metrics = pd.concat([train_metrics, test_metrics], axis=1)\n",
        "    tt_metrics = tt_metrics.rename(\n",
        "        columns={\"Search_train\": \"Search\", \"Model_train\": \"Model\"}\n",
        "    )\n",
        "    tt_metrics\n",
        "    return tt_metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a1089e4c",
      "metadata": {
        "id": "a1089e4c"
      },
      "outputs": [],
      "source": [
        "# train = kc_op_train.copy()\n",
        "# val = kc_op_val.copy()\n",
        "# test = kc_op_test.copy()\n",
        "# target = \"target\"\n",
        "# model_names\n",
        "\n",
        "# # \"2class\"\n",
        "# model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "078062bb",
      "metadata": {
        "id": "078062bb"
      },
      "outputs": [],
      "source": [
        "def run_eval(input_data, target, model_names, model_path, metric_to_optimize):\n",
        "    all_models_tvt_comp = pd.DataFrame()\n",
        "\n",
        "    X = input_data.drop([target], axis=1)\n",
        "    y = input_data[target]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "    print(X_train.shape, y_train.shape)\n",
        "    print(X_test.shape, y_test.shape)\n",
        "\n",
        "    for m in model_names:\n",
        "        model_obj, cv_results = modelTraining(m, X_train, y_train, metric_to_optimize)\n",
        "\n",
        "        hyp_path = (f'{model_path}/{\"model_building_op/best_parameters/all_hyp_params_\"+ m+ \".csv\"}')\n",
        "        cv_results.to_csv(hyp_path, index=False)\n",
        "\n",
        "        # Save the model as a pickle in a file\n",
        "        pkl_name = (f'{model_path}/{\"model_building_op/pkl_files/pkl_\"+ m+ \".pkl\"}')\n",
        "        joblib.dump(model_obj, pkl_name)\n",
        "\n",
        "        train_data = X_train.copy()\n",
        "        train_data[\"actuals\"] = y_train\n",
        "        train_data[\"preds\"] = model_obj.predict(X_train)\n",
        "        train_data[\"pred_probability\"] = model_obj.predict_proba(X_train)[:, 1]\n",
        "\n",
        "        test_data = X_test.copy()\n",
        "        test_data[\"actuals\"] = y_test\n",
        "        test_data[\"preds\"] = model_obj.predict(X_test)\n",
        "        test_data[\"pred_probability\"] = model_obj.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        # Saving train test val data with actuals and predictions ##\n",
        "        train_path = (f'{model_path}/{\"model_building_op/act_pred_train_test/train_\"+ m+ \".csv\"}')\n",
        "        test_path = (f'{model_path}/{\"model_building_op/act_pred_train_test/test_\"+ m+ \".csv\"}')\n",
        "\n",
        "        train_data.to_csv(train_path, index=False)\n",
        "        test_data.to_csv(test_path, index=False)\n",
        "\n",
        "        train_eval = error_metrics_classification(train_data[\"actuals\"], train_data[\"preds\"])\n",
        "        train_eval.columns = train_eval.columns + \"_train\"\n",
        "\n",
        "        test_eval = error_metrics_classification(test_data[\"actuals\"], test_data[\"preds\"])\n",
        "        test_eval.columns = test_eval.columns + \"_test\"\n",
        "\n",
        "        tvt_eval = pd.concat([train_eval, test_eval], axis=1)\n",
        "        tvt_eval['Model'] = m\n",
        "        # all_tt_model_eval = pd.concat([all_tt_model_eval, tt_eval], axis = 0)\n",
        "\n",
        "        temp_err_path = (f'{model_path}/{\"model_building_op/model_perf/eval_metrics_\"+ m + \".csv\"}')\n",
        "        tvt_eval.to_csv(temp_err_path, index=False)\n",
        "        all_models_tvt_comp = pd.concat([all_models_tvt_comp, tvt_eval], axis=0)\n",
        "        # check Important features\n",
        "        if m in [\"dt\", \"rf\", \"xgb\", 'ada', 'gb']:\n",
        "            feature_importances_df = pd.DataFrame({\"feature\": list(X_train.columns),\n",
        "                                                   \"importance\": model_obj.feature_importances_\n",
        "                                                  }).sort_values(\"importance\", ascending=False)\n",
        "            feature_importances_df.to_csv(f'{model_path}/{\"model_building_op/imp_features/imp_feat_\"+ m+ \".csv\"}',index=False)\n",
        "    err_path = (f'{model_path}/{\"model_building_op/model_perf/eval_metrics.csv\"}')\n",
        "    all_models_tvt_comp.to_csv(err_path, index=False)\n",
        "    return all_models_tvt_comp\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b3c3d630",
      "metadata": {
        "id": "b3c3d630"
      },
      "outputs": [],
      "source": [
        "def run_eval_smote(input_data, target, model_names, model_path, metric_to_optimize):\n",
        "    all_models_tvt_comp = pd.DataFrame()\n",
        "\n",
        "    X = input_data.drop([target], axis=1)\n",
        "    y = input_data[target]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "    print(X_train.shape, y_train.shape)\n",
        "    print(X_test.shape, y_test.shape)\n",
        "\n",
        "    # transform the dataset\n",
        "    oversample = SMOTE()\n",
        "    X_train_balanced, y_train_balanced = oversample.fit_resample(X_train, y_train)\n",
        "\n",
        "    for m in model_names:\n",
        "        model_obj, cv_results = modelTraining(m, X_train_balanced, y_train_balanced, metric_to_optimize)\n",
        "\n",
        "        hyp_path = (f'{model_path}/{\"model_building_op/best_parameters/all_hyp_params_\"+ m+ \"_smote.csv\"}')\n",
        "        cv_results.to_csv(hyp_path, index=False)\n",
        "\n",
        "        # Save the model as a pickle in a file\n",
        "        pkl_name = (f'{model_path}/{\"model_building_op/pkl_files/pkl_\"+ m+ \"_smote.pkl\"}')\n",
        "        joblib.dump(model_obj, pkl_name)\n",
        "\n",
        "\n",
        "        train_data = X_train.copy()\n",
        "        train_data[\"actuals\"] = y_train\n",
        "        train_data[\"preds\"] = model_obj.predict(X_train)\n",
        "        train_data[\"pred_probability\"] = model_obj.predict_proba(X_train)[:, 1]\n",
        "\n",
        "        test_data = X_test.copy()\n",
        "        test_data[\"actuals\"] = y_test\n",
        "        test_data[\"preds\"] = model_obj.predict(X_test)\n",
        "        test_data[\"pred_probability\"] = model_obj.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        # Saving train test val data with actuals and predictions ##\n",
        "        train_path = (f'{model_path}/{\"model_building_op/act_pred_train_test/train_\"+ m+ \"_smote.csv\"}')\n",
        "        test_path = (f'{model_path}/{\"model_building_op/act_pred_train_test/test_\"+ m+ \"_smote.csv\"}')\n",
        "\n",
        "        train_data.to_csv(train_path, index=False)\n",
        "        test_data.to_csv(test_path, index=False)\n",
        "\n",
        "        train_eval = error_metrics_classification(train_data[\"actuals\"], train_data[\"preds\"])\n",
        "        train_eval.columns = train_eval.columns + \"_train\"\n",
        "\n",
        "        test_eval = error_metrics_classification(test_data[\"actuals\"], test_data[\"preds\"])\n",
        "        test_eval.columns = test_eval.columns + \"_test\"\n",
        "\n",
        "        tvt_eval = pd.concat([train_eval, test_eval], axis=1)\n",
        "        tvt_eval['Model'] = m\n",
        "        # all_tt_model_eval = pd.concat([all_tt_model_eval, tt_eval], axis = 0)\n",
        "\n",
        "        temp_err_path = (f'{model_path}/{\"model_building_op/model_perf/eval_metrics_\"+ m + \"_smote.csv\"}')\n",
        "        tvt_eval.to_csv(temp_err_path, index=False)\n",
        "        all_models_tvt_comp = pd.concat([all_models_tvt_comp, tvt_eval], axis=0)\n",
        "        # check Important features\n",
        "        if m in [\"dt\", \"rf\", \"xgb\", 'ada', 'gb']:\n",
        "            feature_importances_df = pd.DataFrame({\"feature\": list(X_train.columns),\n",
        "                                                   \"importance\": model_obj.feature_importances_\n",
        "                                                  }).sort_values(\"importance\", ascending=False)\n",
        "            feature_importances_df.to_csv(f'{model_path}/{\"model_building_op/imp_features/imp_feat_\"+ m+ \"_smote.csv\"}',index=False)\n",
        "    err_path = (f'{model_path}/{\"model_building_op/model_perf/eval_metrics_smote.csv\"}')\n",
        "    all_models_tvt_comp.to_csv(err_path, index=False)\n",
        "    return all_models_tvt_comp\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# exp_code = 'experiment_250'\n",
        "# model_names = models\n",
        "# monitor = 'f1'"
      ],
      "metadata": {
        "id": "mmwKRyBKLrFx"
      },
      "id": "mmwKRyBKLrFx",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e2aa25fd",
      "metadata": {
        "id": "e2aa25fd"
      },
      "outputs": [],
      "source": [
        "def run_experiment(exp_code, model_names, monitor):\n",
        "\n",
        "    # Record the start time\n",
        "    start_time = time.time()\n",
        "\n",
        "    version_path = \"/content/drive/My Drive/keratoconus/data/model_versions/\"\n",
        "    model_version = exp_code\n",
        "    artifacts = ['bin_class','eval_metrics','model_building_op']\n",
        "    model_artifacts = ['act_pred_train_test', 'best_parameters','imp_features','model_perf', 'pkl_files']\n",
        "\n",
        "    datasets_path = f'{version_path}/{model_version}/{\"datasets\"}'\n",
        "    model_path = f'{version_path}/{model_version}/{\"training\"}'\n",
        "\n",
        "    print(datasets_path)\n",
        "    print(model_path)\n",
        "\n",
        "    # Record the start time\n",
        "    start_time = time.time()\n",
        "\n",
        "    version_path = \"/content/drive/My Drive/keratoconus/data/model_versions/\"\n",
        "    model_version = exp_code\n",
        "    artifacts = ['bin_class','eval_metrics','model_building_op']\n",
        "    model_artifacts = ['act_pred_train_test', 'best_parameters','imp_features','model_perf', 'pkl_files']\n",
        "\n",
        "    datasets_path = f'{version_path}/{model_version}/{\"datasets\"}'\n",
        "    model_path = f'{version_path}/{model_version}/{\"training\"}'\n",
        "\n",
        "    print(datasets_path)\n",
        "    print(model_path)\n",
        "\n",
        "    kc_op = pd.read_csv(f'{datasets_path}/{\"kc_op.csv\"}')\n",
        "    print(kc_op.shape)\n",
        "\n",
        "    kc_op = kc_op.drop(['uid', 'image_ref'], axis = 1)\n",
        "    print(kc_op.shape)\n",
        "\n",
        "    run_eval_smote(kc_op, 'target', model_names, model_path, monitor)\n",
        "    run_eval(kc_op, 'target', model_names, model_path, monitor)\n",
        "\n",
        "\n",
        "    # Record the end time\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate the time taken\n",
        "    time_taken = end_time - start_time\n",
        "\n",
        "    # Print the start time, end time, and time taken\n",
        "    print(f\"Start Time: {time.ctime(start_time)}\")\n",
        "    print(f\"End Time: {time.ctime(end_time)}\")\n",
        "    print(f\"Time Taken: {time_taken:.2f} seconds\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "73ac3f60",
      "metadata": {
        "id": "73ac3f60"
      },
      "outputs": [],
      "source": [
        "models = [\"ada\", \"gb\", \"lr\", \"dt\", \"rf\", \"xgb\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_experiment('experiment_252', models, 'f1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_HXLJ4K7EiX",
        "outputId": "1f6228e7-5e68-4a20-cb58-7344c2928031"
      },
      "id": "9_HXLJ4K7EiX",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/keratoconus/data/model_versions//experiment_252/datasets\n",
            "/content/drive/My Drive/keratoconus/data/model_versions//experiment_252/training\n",
            "/content/drive/My Drive/keratoconus/data/model_versions//experiment_252/datasets\n",
            "/content/drive/My Drive/keratoconus/data/model_versions//experiment_252/training\n",
            "(2576, 24)\n",
            "(2576, 22)\n",
            "(1803, 21) (1803,)\n",
            "(773, 21) (773,)\n",
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
            "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
            "Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n",
            "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
            "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n",
            "(1803, 21) (1803,)\n",
            "(773, 21) (773,)\n",
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
            "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
            "Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n",
            "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
            "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n",
            "Start Time: Wed Jul 31 08:52:47 2024\n",
            "End Time: Wed Jul 31 10:28:34 2024\n",
            "Time Taken: 5747.06 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_experiment('experiment_251', models, 'f1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXggOvSj7Fyt",
        "outputId": "55c0342b-dfd2-40b2-9db4-f1c753a3e89c"
      },
      "id": "AXggOvSj7Fyt",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/keratoconus/data/model_versions//experiment_251/datasets\n",
            "/content/drive/My Drive/keratoconus/data/model_versions//experiment_251/training\n",
            "/content/drive/My Drive/keratoconus/data/model_versions//experiment_251/datasets\n",
            "/content/drive/My Drive/keratoconus/data/model_versions//experiment_251/training\n",
            "(1555, 24)\n",
            "(1555, 22)\n",
            "(1088, 21) (1088,)\n",
            "(467, 21) (467,)\n",
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
            "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
            "Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n",
            "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
            "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n",
            "(1088, 21) (1088,)\n",
            "(467, 21) (467,)\n",
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
            "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
            "Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n",
            "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
            "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n",
            "Start Time: Wed Jul 31 10:28:34 2024\n",
            "End Time: Wed Jul 31 11:29:28 2024\n",
            "Time Taken: 3654.85 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17300673",
      "metadata": {
        "scrolled": true,
        "id": "17300673",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6cef124-1d9d-431f-971d-7e1a31e6e9f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/keratoconus/data/model_versions//experiment_250/datasets\n",
            "/content/drive/My Drive/keratoconus/data/model_versions//experiment_250/training\n",
            "/content/drive/My Drive/keratoconus/data/model_versions//experiment_250/datasets\n",
            "/content/drive/My Drive/keratoconus/data/model_versions//experiment_250/training\n",
            "(4131, 24)\n",
            "(4131, 22)\n",
            "(2891, 21) (2891,)\n",
            "(1240, 21) (1240,)\n",
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
            "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
            "Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n",
            "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
            "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n",
            "(2891, 21) (2891,)\n",
            "(1240, 21) (1240,)\n",
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n"
          ]
        }
      ],
      "source": [
        "run_experiment('experiment_250', models, 'f1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ee05e00",
      "metadata": {
        "id": "6ee05e00"
      },
      "outputs": [],
      "source": [
        "# 'experiment_250'\n",
        "\n",
        "# /content/drive/My Drive/keratoconus/data/model_versions//experiment_250/datasets\n",
        "# /content/drive/My Drive/keratoconus/data/model_versions//experiment_250/training\n",
        "# /content/drive/My Drive/keratoconus/data/model_versions//experiment_250/datasets\n",
        "# /content/drive/My Drive/keratoconus/data/model_versions//experiment_250/training\n",
        "# (4131, 24)\n",
        "# (4131, 22)\n",
        "# (2891, 21) (2891,)\n",
        "# (1240, 21) (1240,)\n",
        "# Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
        "# Fitting 5 folds for each of 3240 candidates, totalling 16200 fits\n",
        "# Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
        "# Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n",
        "# Fitting 5 folds for each of 3200 candidates, totalling 16000 fits\n",
        "# Fitting 5 folds for each of 6480 candidates, totalling 32400 fits\n",
        "# (2891, 21) (2891,)\n",
        "# (1240, 21) (1240,)\n",
        "# Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
        "# Fitting 5 folds for each of 3240 candidates, totalling 16200 fits\n",
        "# Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
        "# Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n",
        "# Fitting 5 folds for each of 3200 candidates, totalling 16000 fits\n",
        "# Fitting 5 folds for each of 6480 candidates, totalling 32400 fits\n",
        "# Start Time: Mon Jul 29 07:31:39 2024\n",
        "# End Time: Mon Jul 29 14:30:51 2024\n",
        "# Time Taken: 25152.33 seconds"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}